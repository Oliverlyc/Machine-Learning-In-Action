{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树的任务是为了理解数据中所蕴含的知识信息    \n",
    "- 优点：计算复杂度不高，输出结果易于理解，对中间值缺失不敏感，可以处理不相关的特征数据    \n",
    "- 缺点：可能会出现过度匹配（过拟合）    \n",
    "- 适用数据类型：数值型和标称型    \n",
    "\n",
    "本示例使用[ID3算法](https://www.cnblogs.com/yjd_hycf_space/p/6940068.html)  \n",
    "\n",
    "在决策树的每一个非叶子结点划分之前，先计算每一个属性所带来的信息增益，选择最大信息增益的属性来划分，因为信息增益越大，区分样本的能力就越强，越具有代表性，很显然这是一种自顶向下的贪心策略    \n",
    "\n",
    "香农熵公式$H = -\\sum^{n}_{i=1}p(x_i)\\log_2p(x_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet = [[1, 1, 'yes'],\n",
    "                    [1, 1, 'yes'],\n",
    "                    [1, 0, 'no'],\n",
    "                    [0, 1, 'no'],\n",
    "                    [0, 1, 'no']]\n",
    "labels = ['no surfacing', 'flippers']\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算香农熵\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)#实例总数\n",
    "    labelCounts = {} #标签出现次数\n",
    "    shannonEnt = 0.0\n",
    "    for featVet in dataSet:\n",
    "        currentLabel = featVet[-1] \n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob, 2) #信息量公式\n",
    "    return shannonEnt\n",
    "\n",
    "# 划分数据集\n",
    "'''\n",
    "@功能：划分数据集\n",
    "@params list dataSet 数据集\n",
    "@params axis 需要划分的特征(比如，是否有会游泳)Index\n",
    "@params value 返回的特征的值(比如，会，不会)\n",
    "'''\n",
    "#这里需要注意的是python在函数中传递的是列表的引用，如果修改了传入的数据，会对源数据产生影响\n",
    "def splitDataset(dataSet, axis, value):\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value: #判断数据集中的特征的值是否等于value\n",
    "            tmpVec = featVec[:axis]\n",
    "            tmpVec.extend(featVec[axis+1:]) #取出划分的特征，返回其他特征，extent是追加元素\n",
    "            retDataSet.append(tmpVec) #追加列表\n",
    "    return retDataSet\n",
    "'''\n",
    "@功能：选择最好的数据集划分方式\n",
    "@params list dataSet 数据集\n",
    "'''\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    featuresCounts = len(dataSet[0])-1 #特征个数\n",
    "    baseEntropy = calcShannonEnt(dataSet) #初始信息熵\n",
    "    bastInfoGain = 0.0; #初始化信息增益\n",
    "    bestFeatureIndex = -1 #初始化\n",
    "    for i in range(featuresCounts):\n",
    "        featList = [tmp[i] for tmp in dataSet] #属性值List\n",
    "        uniqueFeat = set(featList) #唯一属性值集合\n",
    "        newEntropy = 0.0 #初始化信息熵\n",
    "        for value in uniqueFeat:\n",
    "            subDataSet = splitDataset(dataSet, i, value) #划分数据集\n",
    "            prob = len(subDataSet)/float(len(dataSet))  #概率\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        infoGain = baseEntropy-newEntropy #信息增益\n",
    "        if(infoGain > bastInfoGain): #比较信息增益\n",
    "            bastInfoGain = infoGain\n",
    "            bestFeatureIndex = i\n",
    "    return bestFeatureIndex\n",
    "\n",
    "'''\n",
    "@功能 多数表决 用来处理label已经用完 但是还有其他特征值的情况\n",
    "@param list classList\n",
    "'''\n",
    "def majorityCnt(classList):\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "'''\n",
    "@功能 递归创建决策树\n",
    "@param list dataSet\n",
    "@param list labels\n",
    "'''\n",
    "def createTree(dataSet, labels):\n",
    "    classList = [example[-1] for example in dataSet] #分类的列表\n",
    "    if classList.count(classList[0]) == len(classList): #如果类别完全相同，停止划分\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList) #遍历所有特征，返回出现次数最多的类别\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet) #选择最好的数据划分方式\n",
    "    bestFeatureLabel = labels[bestFeat] #最好的特征标签\n",
    "    myTree = {bestFeatureLabel:{}}\n",
    "    del(labels[bestFeat])#删除标签\n",
    "    featValues = [example[bestFeat] for example in dataSet] #特征属性值列表\n",
    "    uniqueVals = set(featValues)#确定每个属性的唯一性\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        myTree[bestFeatureLabel][value] = createTree(splitDataset(dataSet, bestFeat, value), subLabels)#递归\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709505944546686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def file2matrix():\n",
    "print(calcShannonEnt(dataSet))\n",
    "file = open(\"./lenses.txt\",\"r\")\n",
    "content = file.readlines()\n",
    "chooseBestFeatureToSplit(dataSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createTree(dataSet, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-f042b22054d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "dataSet[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
